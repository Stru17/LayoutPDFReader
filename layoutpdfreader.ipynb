{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd73305c",
      "metadata": {
        "id": "cd73305c"
      },
      "source": [
        "# PDF Analysis and Querying using LLMSherpa and OpenAI\n",
        "This notebook demonstrates the process of analyzing a PDF document using LLMSherpa and LlamaIndex, integrated with OpenAI's API for natural language processing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llmsherpa\n",
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "hYiWMXz6pAiQ"
      },
      "id": "hYiWMXz6pAiQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4f65c1a2",
      "metadata": {
        "id": "4f65c1a2"
      },
      "outputs": [],
      "source": [
        "import llmsherpa\n",
        "from llmsherpa.readers import LayoutPDFReader\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.readers.schema.base import Document\n",
        "from llama_index import VectorStoreIndex\n",
        "import openai\n",
        "from IPython.core.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "848aa591",
      "metadata": {
        "id": "848aa591"
      },
      "outputs": [],
      "source": [
        "# Load LLMSherpa API and PDF\n",
        "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
        "pdf_url = \"https://omscs.gatech.edu/sites/default/files/documents/Other_docs/spring_2023_orientation_document.pdf\" # also can do file path\n",
        "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
        "doc = pdf_reader.read_pdf(pdf_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6ee7f1e2",
      "metadata": {
        "id": "6ee7f1e2"
      },
      "outputs": [],
      "source": [
        "# Insert OpenAI API key\n",
        "openai.api_key = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b4cecf",
      "metadata": {
        "id": "e7b4cecf"
      },
      "source": [
        "## Method 1: Manually select a Specific Section and feed to ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e1ffb16",
      "metadata": {
        "id": "8e1ffb16"
      },
      "outputs": [],
      "source": [
        "selected_section = None\n",
        "x = 0\n",
        "for section in doc.sections():\n",
        "    if section.title == 'SECTION B. FOUNDATIONAL COURSE REQUIREMENT' and x == 1:\n",
        "        selected_section = section\n",
        "        break\n",
        "    elif section.title == 'SECTION B. FOUNDATIONAL COURSE REQUIREMENT':\n",
        "        x += 1\n",
        "HTML(selected_section.to_html(include_children = True, recurse = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82eceba9",
      "metadata": {
        "id": "82eceba9"
      },
      "outputs": [],
      "source": [
        "context = selected_section.to_html(include_children=True, recurse=True)\n",
        "question = \"list all the tasks discussed and one line about each task\"\n",
        "resp = OpenAI().complete(f\"read this text and answer question: {question}:{context}\")\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c19782",
      "metadata": {
        "id": "f3c19782"
      },
      "source": [
        "## Method 2: Vector Search and RAG with Smart Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c429d0",
      "metadata": {
        "id": "11c429d0"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex([])\n",
        "for chunk in doc.chunks():\n",
        "    index.insert(Document(text=chunk.to_context_text(), extra_info={}))\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"what are some key points in foundational course requirement\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"what are the systems in the table for SECTION I. SYSTEMS YOU WILL BE USING AND WHY\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "AsH2JLK0pQsG"
      },
      "id": "AsH2JLK0pQsG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4afe7bee",
      "metadata": {
        "id": "4afe7bee"
      },
      "source": [
        "## Extra: Parse through tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "062cb090",
      "metadata": {
        "id": "062cb090"
      },
      "outputs": [],
      "source": [
        "# Table parsing method (not always perfect)\n",
        "HTML(doc.tables()[11].to_html())\n",
        "context = doc.tables()[11].to_html()\n",
        "resp = OpenAI().complete(f\"read this table and answer question: what are the systems in the table for SECTION I. SYSTEMS YOU WILL BE USING AND WHY:\\n{context}\")\n",
        "print(resp.text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}